{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYDE 675 --- Assignment 1\n",
    "**Student ID: 20823934**\n",
    "\n",
    "*Note:* Please include your numerical student ID only, do *not* include your name.\n",
    "\n",
    "*Note:* Cells you need to fill out are marked with a \"writing hand\" symbol. Of course, you can add new cells in between the instructions, but please leave the instructions intact to facilitate marking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta\n",
    "\n",
    "# Fix the numpy random seed for reproducible results\n",
    "np.random.seed(18945)\n",
    "\n",
    "# Some formating options\n",
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Programming\n",
    "\n",
    "## 3.1 Overcoming a Prior\n",
    "\n",
    "As we covered in class, the Beta distribution is the conjugate prior to a Bernoulli distribution.  Here we will generate observations from $n$ coin flips from an unfair coin with probability of a heads as $P(H=1) = p$, where the true value is $p=0.3$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_coin(p=0.3, num_flips=1):\n",
    "    return (np.random.uniform(low=0,high=1,size=(num_flips,)) < p).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compute a posterior distribution for $p$ by updating a Beta distribution using observations from the above ```flip_coin``` function.  To illustrate the effect a prior can have, we will compute the posterior distribution using a \"good\", \"bad\", and \"uninformative\" set of parameters, the \"pseudocounts\" discussed in class. \n",
    "\n",
    "| Condition | $a$ | $b$ | \n",
    "|:--- |:---:|:---:|\n",
    "| Good | 1 | 2 |\n",
    "| Bad | 10 | 1 | \n",
    "| Uninformative | 1 | 1 |\n",
    "\n",
    "Below we show how to evaluate the PDF of a Beta distribution given parameters $a$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_condition = {'a':10,'b':30}\n",
    "bad_condition = {'a':10,'b':1}\n",
    "uninformative_condition = {'a':1,'b':1}\n",
    "\n",
    "ps = np.linspace(0,1,100) # The true p lies in the range [0,1], want to evalute ps.\n",
    "\n",
    "cond_names = ['Good','Bad','Uninformative']\n",
    "plt.figure(figsize=(10,5))\n",
    "for cond_idx, condition in enumerate([good_condition, bad_condition, uninformative_condition]):\n",
    "    plt.subplot(1,3,1+cond_idx)\n",
    "\n",
    "    beta_rv = beta(a=condition['a'],b=condition['b'])\n",
    "    plt.plot(ps, beta_rv.pdf(ps), label='Prior')    # Plots the Beta probability density function between 0 and 1 at 100 decimal points\n",
    "    plt.title(cond_names[cond_idx])\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to \n",
    "\n",
    "1. Compute and plot the posterior distribution over $p$ for each condition, for $n \\in \\{10,100,1000,10000\\}$.\n",
    "2. For each condition, plot the error in the MAP estimate of $p$ as a function of $n$.\n",
    "\n",
    "Hints: \n",
    "\n",
    "1. The Beta distribution is the conjugate prior for the Bernoulli distribution.\n",
    "1. The MAP estimate will be the value of $p \\in [0,1]$ for which the posterior PDF takes on a maximum value.  \n",
    "2. For the purposes of this assigment, you can approximate the MAP estimate by finely sampling the domain $[0,1]$, say 100 sample points, _i.e._, ```ps = np.linspace(0,1,100)```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ \\<YOUR SOLUTION HERE\\>\n",
    "\n",
    "ns = [10, 100, 1000, 10000]\n",
    "\n",
    "# 1. Compute and plot the posterior distribution over p for each condition and each n\n",
    "np.random.seed(18945)\n",
    "plt.figure(figsize=(10,5))\n",
    "for cond_idx, condition in enumerate([good_condition, bad_condition, uninformative_condition]):\n",
    "    # Aim the lines at the appropriate subplot\n",
    "    plt.subplot(1,3,1+cond_idx)    \n",
    "    for n in ns:\n",
    "        # Overcome the conjugate prior by updating it with more flips\n",
    "        additional_flips = flip_coin(num_flips=n)\n",
    "        new_a = condition['a'] + np.sum(additional_flips)\n",
    "        new_b = condition['b'] + n - np.sum(additional_flips)\n",
    "        beta_rv = beta(a=new_a, b=new_b)\n",
    "        \n",
    "        plt.plot(ps, beta_rv.pdf(ps), label=f'n={n}')\n",
    "    \n",
    "    # Plot the initial prior\n",
    "    beta_rv = beta(a=condition['a'],b=condition['b'])\n",
    "    plt.plot(ps, beta_rv.pdf(ps), label='Prior')\n",
    "    \n",
    "    plt.title(cond_names[cond_idx])\n",
    "    plt.xlabel('p')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# 2. For each condition, plot the error in the MAP estimate of p as a function of n\n",
    "np.random.seed(18945)\n",
    "plt.figure(figsize=(10,5))\n",
    "for cond_idx, condition in enumerate([good_condition, bad_condition, uninformative_condition]):\n",
    "    plt.subplot(1,3,1+cond_idx)\n",
    "    errors = []\n",
    "    for n in ns:\n",
    "        # Overcome the conjugate prior by updating it with more flips\n",
    "        additional_flips = flip_coin(num_flips=n)\n",
    "        new_a = condition['a'] + np.sum(additional_flips)\n",
    "        new_b = condition['b'] + n - np.sum(additional_flips)\n",
    "        beta_rv = beta(a=new_a, b=new_b)\n",
    "        \n",
    "        # The MAP estimate is the value of p for which the posterior PDF has the max value\n",
    "        # Use the absolute error\n",
    "        map_estimate = ps[np.argmax(beta_rv.pdf(ps))]\n",
    "        errors.append(np.abs(map_estimate - 0.3))\n",
    "    plt.plot(ns, errors, 'o-')\n",
    "    plt.title(cond_names[cond_idx])\n",
    "    plt.xlabel('n')\n",
    "    plt.ylabel('Error')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "Regardless of the quality of the conjugate prior, the addition of additional observations was able to overcome it and give a more accurate estimate of the true Heads probability. The top three plots show that the posterior PDF converge to around `p=0.3` as more samples are taken. The bottom three plots confirm this by showing a lower error rate as a function of n. However, none of the cases obtained zero error, as sampling is still an estimation technique. Additionally, even though the error decreased monotonically for this seed, such results are not guaranteed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Classification with a Kernel Density Estimator.\n",
    "\n",
    "Here we will use the Scikit-Learn kernel density estimator to construct a Bayesian classifier.  We will test it using the two moons data set.  \n",
    "\n",
    "Remember that given a dataset of observations $S = ((x_{1},y_{1}),\\ldots,(x_{m},y_{m}))$ and a kernel density estimator $p(x\\mid (x_{1},\\ldots,x_{m}))$, we can construct our Bayesian classifier using the following elements:\n",
    "\n",
    "\n",
    "1. The likelihood is approximated: $p(x \\mid C = c) = p(x \\mid \\{x_{i} \\in S\\mid_{x} : y_{i} = c\\})$.  \n",
    "1. The marginal distribution for $x$ is approximated: $p(x) = p(x \\mid S\\mid_{x})$, \n",
    "1. The prior is approximated $p(C=c) = \\frac{|\\{y_{i} \\in S\\mid_{y} : y_{i} = c\\}|}{|S\\mid_{y}|}$,  Note that we can implement this with a simple histogram with 2 bins for a binary classification.\n",
    "\n",
    "Let us generate some data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_samples = 100\n",
    "num_testing_samples = 100\n",
    "\n",
    "colors = ['tab:blue','tab:orange']\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "np.random.seed(0)\n",
    "X_train, y_train = make_moons(n_samples=num_training_samples, noise=0.1)\n",
    "X_test, y_test = make_moons(n_samples=num_testing_samples, noise=0.1)\n",
    "\n",
    "\n",
    "plt.scatter(X_train[:,0], X_train[:,1],color=[colors[y.astype(int)] for y in y_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to fit a kernel density estimator.  We will use SciKit Learn's Kernel Density Estimator to fit the training data.  We will use a Gaussian kernel. We will modify the _length scale_ or _bandwidth_ parameter to change the performance of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=1).fit(X_train)\n",
    "\n",
    "prob_train = np.exp(kde.score_samples(X_train)) # score_samples returns the log probability\n",
    "prob_test = np.exp(kde.score_samples(X_test))\n",
    "plt.scatter(X_train[:,0], X_train[:,1], marker='x', c=prob_train, label='Train')\n",
    "plt.scatter(X_test[:,0], X_test[:,1], marker='o', c=prob_test, label='Test')\n",
    "plt.colorbar()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the above, we computed the probability the samples using the statement ```np.exp(kde.score_samples(X_train))```.\n",
    "We exponentiate the ```score_samples``` function because it returns the log probability, as opposed to just the probability.\n",
    "\n",
    "Next you will construct the classifier using a kernel density estimator for the whole data set (as constructed above), one just for class 0 samples, and another just for class 1 samples. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_error(y_true, y_pred):\n",
    "    return np.mean(y_true != y_pred)\n",
    "\n",
    "# Using a trained classifier to predict the class of the test samples\n",
    "def classifier(x_test, kde_0, kde_1, kde_marginal, prior):\n",
    "    likelihood_0 = np.exp(kde_0.score_samples(x_test))          # ✍ p(x | D_0) --> Use the KDE for class 0\n",
    "    likelihood_1 = np.exp(kde_1.score_samples(x_test))          # ✍ p(x | D_1) --> Use the KDE for class 1\n",
    "    marginal_prob = np.exp(kde_marginal.score_samples(x_test))  # ✍ p(x | D) --> Get the marginal probability\n",
    "    posterior_0 = likelihood_0 * prior / marginal_prob          # ✍ p(C=0|x) = p(x|C=0)p(C=0)/p(x) --> Assume prior is for class 0\n",
    "    posterior_1 = likelihood_1 * (1 - prior) / marginal_prob    # ✍ p(C=1|x) = p(x|C=1)p(C=1)/p(x)\n",
    "    \n",
    "    return np.argmax([posterior_0, posterior_1], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will compute the testing and training classification error, which is the classification performance on the testing and training sets using KDEs that are fit using only the training data set.\n",
    "\n",
    "Below you will plot the classification error, which you can compute using the ```sklearn.metrics.zero_one_loss``` function.  Plot the classification errors as a function of the kernel bandwidth, testing values of $h \\in \\{0.01,0.1,1,10,100\\}$.  Use the same kernel bandwidth for all three estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ \\<YOUR SOLUTION HERE\\>\n",
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "def plot_classification_error(kernel='gaussian', num_training_samples=100, num_testing_samples=100, seed=0):\n",
    "    np.random.seed(seed)\n",
    "    X_train, y_train = make_moons(n_samples=num_training_samples, noise=0.1)\n",
    "    X_test, y_test = make_moons(n_samples=num_testing_samples, noise=0.1)\n",
    "    \n",
    "    bandwidths = [0.01, 0.1, 1, 10, 100]\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    for bandwidth in bandwidths:\n",
    "        kde_0 = KernelDensity(kernel=kernel, bandwidth=bandwidth).fit(X_train[y_train == 0])    # Fit using only the training set\n",
    "        kde_1 = KernelDensity(kernel=kernel, bandwidth=bandwidth).fit(X_train[y_train == 1])\n",
    "        kde_marginal = KernelDensity(kernel=kernel, bandwidth=1).fit(X_train)\n",
    "        prior = np.mean(y_train == 0)   # Assume prior is for class 0\n",
    "        \n",
    "        y_train_pred = classifier(X_train, kde_0, kde_1, kde_marginal, prior)\n",
    "        train_errors.append(zero_one_loss(y_train, y_train_pred))   # Use zero-one loss which is the same as classification_error()\n",
    "        \n",
    "        y_test_pred = classifier(X_test, kde_0, kde_1, kde_marginal, prior)\n",
    "        test_errors.append(zero_one_loss(y_test, y_test_pred))\n",
    "        \n",
    "    plt.plot(bandwidths, train_errors, 'o-', label='Train')\n",
    "    plt.plot(bandwidths, test_errors, 'o-', label='Test')\n",
    "    plt.xscale('log')\n",
    "    plt.title(f'Kernel: {kernel}, Train samples: {num_training_samples}, Test samples: {num_testing_samples}')\n",
    "    plt.xlabel('Bandwidth')\n",
    "    plt.ylabel('Classification Error')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_classification_error(kernel='gaussian', num_training_samples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the above process for a Top Hat kernel with $n=100$ training sample points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ \\<YOUR SOLUTION HERE\\>\n",
    "plot_classification_error(kernel='tophat', num_training_samples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the process for a Gaussian kernel with $n=400$ training sample points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍ \\<YOUR SOLUTION HERE\\>\n",
    "plot_classification_error(kernel='gaussian', num_training_samples=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "All three setups exhibit signs of overfitting, where the training loss is lower than the test loss. This is especially evident with the Top Hat kernel, which has 0 train error when `h = 0.01` but 0.5 test error. In all three setups, the error increases with bandwidth, which makes sense because generalization leads to loss of precision. Both Gaussian kernels were able to achieve 0 train and test loss with `h = 0.01` and `h = 0.1`, and there's not much difference in error at the larger bandwidths. However, `train samples = 400` had slightly higher test error, which could indicate increased overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "highway",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
